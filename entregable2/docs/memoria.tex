\documentclass[]{article}
\usepackage{graphicx}
\usepackage[spanish]{babel}
\usepackage[a4paper, top=2.5cm, bottom=2.5cm, left=3cm, right=3cm]{geometry}
\usepackage[hidelinks]{hyperref}
\usepackage[T1]{fontenc}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{float}

\definecolor{miverde}{rgb}{0,0.6,0}

% style for listings (código)
\lstdefinestyle{python}{
    language=Python,
    backgroundcolor=\color{gray!2},     % Color de fondo
    basicstyle=\ttfamily,               % Tipo y tamaño de fuente
    keywordstyle=\color{blue}\bfseries, % Color para palabras clave
    stringstyle=\color{miverde},        % Color para cadenas
    commentstyle=\color{red},           % Color para comentarios
    showspaces=false,                   % No mostrar espacios
    showstringspaces=false,             % No mostrar espacios en las cadenas
    frame=single,                       % Poner un marco alrededor del código
    breaklines=true,                    % Romper las líneas largas
    captionpos=b,                       % Posición del caption
    tabsize=4,                          % Tamaño de las tabulaciones
    escapeinside={\%*}{*)},             % Para incluir código LaTeX en los listings
    morekeywords={self}                 % Palabras clave adicionales
}

\lstdefinestyle{bash}{
    language=shell,
    backgroundcolor=\color{gray!2},     % Color de fondo
    basicstyle=\ttfamily,               % Tipo y tamaño de fuente
    keywordstyle=\color{blue}\bfseries, % Color para palabras clave
    stringstyle=\color{miverde},        % Color para cadenas
    commentstyle=\color{red},           % Color para comentarios
    showspaces=false,                   % No mostrar espacios
    showstringspaces=false,             % No mostrar espacios en las cadenas
    frame=single,                       % Poner un marco alrededor del código
    breaklines=true,                    % Romper las líneas largas
    captionpos=b,                       % Posición del caption
    tabsize=4,                          % Tamaño de las tabulaciones
    escapeinside={\%*}{*)},             % Para incluir código LaTeX en los listings
    morekeywords={self}                 % Palabras clave adicionales
}

\lstset{basicstyle=\ttfamily}
\lstset{
    inputencoding=utf8,
    extendedchars=true,      % Permitir caracteres extendidos (acentos)
    literate=%
        {á}{{\'a}}1 {Á}{{\'A}}1
        {é}{{\'e}}1 {É}{{\'E}}1
        {í}{{\'i}}1 {Í}{{\'I}}1
        {ó}{{\'o}}1 {Ó}{{\'O}}1
        {ú}{{\'u}}1 {Ú}{{\'U}}1
}


%title
\title{Práctica 2} 

\author{Adrián Ferández Galán, César López Mantecón y Manuel Gómez-Plana Rodríguez}

\begin{document}

\begin{titlepage}
    \centering
   \includegraphics[width=0.9\textwidth]{uc3m.jpg} 
    {\Huge Universidad Carlos III\\
    
     \Large Arquitectura de Datos\\
     \vspace{0.5cm}
     Curso 2024-25}
    \vspace{2cm}

    {\Huge \textbf{Práctica 1.2} \par}
    \vspace{0.5cm}
    {\Large Migración de Base de Datos a MongoDB \par}
    \vspace{8cm}

   \textbf{Ingeniería Informática, Cuarto curso}\\
    \vspace{0.2cm} 
    Adrián Fernández Galán       (NIA: 100472182, e-mail: 100472182@alumnos.uc3m.es)\\
    César López Mantecón         (NIA: 100472092, e-mail: 100472092@alumnos.uc3m.es)\\
    Manuel Gómez-Plana Rodríguez (NIA: 100472310, e-mail: 100472310@alumnos.uc3m.es)
    \vspace{0.5cm}

   
    \textbf{Prof.} Lourdes Moreno López\\
    
    \textbf{Grupo: } 81   
    
\end{titlepage}
\newpage

\renewcommand{\contentsname}{\centering Índice}
\tableofcontents

\newpage
\section{Introducción}
\label{sec:introduccion}
En este documento se recoge el desarrollo de la segunda práctica de la asignatura Arquitectura de datos. A continuación, se especifica el preprocesado de los datos usando la biblioteca \textit{Pandas} de Python, la realización de la validación de esquemas de mongoDB y la carga de los csvs limpios a esta herramienta.

\newpage
\lstset{style=python}
\section{Preprocesado de Datos}
\label{sec:preprocesado}
En este apartado se describen las técnicas más comunes para el preprocesado de los datos sucios, así como las técnicas especificas para los csvs con datos menos genéricos. Para este preprocesado se ha usado la librería de Python \textit{Pandas}, siguiendo una metodología común para cada fichero que constaba de los siguientes pasos:

\begin{enumerate}
    \item Se carga el csv a limpiar en un \textit{dataframe} de \textit{Pandas}
    \item Se aplican técnicas de preprocesado como la normalización de los strings o imputación genérica de \textit{missing values}
    \item Se escribe el csv limpio a partir del \textit{dataframe} preprocesado
\end{enumerate}

\subsection{Técnicas de preprocesado comunes}
\label{subsec:preprocesadocomun}
Se han aplicado técnicas de preprocesado que son comunes a todos los ficheros, independientemente de cual se quiera limpiar. A continuación, se listan y explican las técnias más usadas:

\begin{itemize}
    \item \textbf{Normalización de strings}:

    Todos los datos categóricos han sido normalizados de manera que siempre estén en mayúscula y sin tildes. Esto se ha realizado empleando la siguiente función:

    \begin{lstlisting}[language=Python]
def change_accents(word):
    if type(word) != str:
        return
    for letter in range(len(word)):
        if word[letter] == "Á":
            word = word[0:letter] + "A" + word[letter + 1:]
        if word[letter] == "É":
            word = word[0:letter] + "E" + word[letter + 1:]
        if word[letter] == "Í":
            word = word[0:letter] + "I" + word[letter + 1:]
        if word[letter] == "Ó":
            word = word[0:letter] + "O" + word[letter + 1:]
        if word[letter] == "Ú":
            word = word[0:letter] + "U" + word[letter + 1:]
    return word
    \end{lstlisting}

    La cuál se llama de la siguiente manera:

    \begin{lstlisting}
dataframe.loc[indice, "COLUMNA_A_CAMBIAR"] = change_accents(valor["COLUMNA_A_CAMBIAR"].upper())
    \end{lstlisting}

    \item \textbf{Rellenado de fechas}

    Las fechas que tenían el valor ``fecha desconocida'' o que no tenían valor han sido rellenadas con el valor ``01/01/1970'' a través del siguiente código:

    \begin{lstlisting}
for indice, value in dataframe.iterrows():
    if not pd.notna(value["FECHA_INSTALACION"]) or value["FECHA_INSTALACION"] == "fecha_incorrecta":
        dataframe.loc[indice, "FECHA_INSTALACION"] = "1970-01-01T00:00:00Z"
    \end{lstlisting}

    Se ha seleccionado este valor por tratarse de la \textit{fecha UNIX}. De
    esta forma es un valor fácilmente reconocible que no inclumple la validación
    de esquemas que implementaremos en \texttt{MongoDB}.

    \item \textbf{Formateo de fechas}

    Todas las fechas han sido formateadas al formato de mongo a través del siguiente código:

    \begin{lstlisting}
dataframe["COLUMNA_A_CAMBIAR"] = pd.to_datetime(dataframe["COLUMNA_A_CAMBIAR"], format="mixed", dayfirst=True, utc=True).dt.strftime('%Y-%m-%dT%H:%M:%SZ')
    \end{lstlisting}

    Se ha seleccionado este valor por tratarse de la \textit{fecha UNIX}. De
    esta forma es un valor fácilmente reconocible que no inclumple la validación
    \item \textbf{Rellenado genérico de \textit{missing values}}
    
    Las columnas que tenían valores nulos que no ha sido posible imputar han sido rellenadas con un valor fácilmente indetificable que sigue el formato ``NOM-COL\_DESCONOCIDO\_ID-FILA'' mediante la siguiente función:

    \begin{lstlisting}
def fill_missing_tipo(row,column,string_missing):
    if pd.isnull(row[column]):
        return f'{string_missing}_{row["ID"]}'
    return row[column]
    \end{lstlisting}

    Esta función se llama de la siguiente manera:

    \begin{lstlisting}
df["COLUMNA"] = df.apply(lambda row: fill_missing_tipo(row, "COLUMA", "COLUMNA_DESCONOCIDO"), axis=1)
    \end{lstlisting}

\end{itemize}

\subsection{Preprocesado de los csvs}
\label{subsec:preprocessespecifico}
En este apartado se explican las técnicas y procedimientos para el preprocesado de cada uno de los csvs sucios.

\subsubsection{Áreas}
\label{subsubsec:preprocessarea}
Para el fichero \textit{AreasSucio.csv} se ha aplicado el siguiente proceso:

\begin{enumerate}
    \item Apertura y carga de valores en dataframe
    \item Normalización de la columna \textit{DESC\_CLASIFICACION}: mediante el paso a mayúsculas y la eliminación de los acentos de toda la columna
    \item Normalización de la columna \textit{BARRIO}: mediante el paso a mayúsculas y eliminación de los acentos de toda la columna, así como la obtención de los valores de \textit{COD\_POSTAL} por barrio para su posterior imputación siempre y cuando sus valores no sean nulos
    \item Imputación de los valores faltantes de \textit{COD\_POSTAL}: mediante la identificación del barrio y la imputación del código postal identificado por el barrio
    \item Normalización de la columna \textit{DISTRITO}: mediante el paso a mayúsculas y eliminación de los acentos de toda la columna, así como la obtención de los valores de \textit{COD\_DISTRITO} por distrito y viceversa para su posterior imputación, siempre y cuando sus valores no sean nulos
    \item Imputación de los valores faltantes de \textit{COD\_DISTRITO} y \textit{DISTRITO}: mediante la identificación del código buscando por distrito cuando este no es nulo y viceversa
    \item Imputación de valores en \textit{TIPO\_VIA}, \textit{NOMBRE\_VIA}, y \textit{NUM\_VIA}: se ha extraído toda la información posible de \textit{DIRECCION\_AUX} y rellenado los campos anteriores en caso posible siguiendo los siguientes pasos:
    \begin{itemize}
        \item Si no hay \textit{TIPO\_VIA}, se extrae el tipo de la dirección auxiliar. Si esta no existe, se escribe el valor ``tipo\_desconocido\_ID''
        \item Si no hay \textit{NOM\_VIA}, se extrae el nombre de la dirección auxiliar. Si esta no existe, se escribe el valor ``NOMBRE\_DESCONOCIDO\_ID''
        \item Si no hay \textit{NUM\_VIA}, se extrae el número de la dirección auxiliar. Aquí, puede haber tres opciones:
        \begin{itemize}
            \item Existe solo un número en la dirección auxiliar, que tiene la forma ``VALDEBERNARDO, 000037''. En este caso, simplemente se extrae y se castea a entero para eliminar los 0's innecesarios
            \item Existen más de un número en la dirección auxiliar, que tiene la forma ``V · VIA LÍMITE 115 , ASCENDIENTE 1: 064 · ALMENAR''. En este caso, se extrae el primer número y se interpreta como el número de la vía
            \item Si no existen números en la dirección auxiliar, que tiene la forma ``PARQUE ROMA''. Aquí, simplemente se escribe el valor ``NUMERO\_DESCONOCIDO\_ID''
        \end{itemize}
        \item Tras sacar los datos de la dirección auxiliar, se borra esta columna de la instancia imputada
    \end{itemize}
    \item Formateo de \textit{FECHA\_INSTALACION}: mediante el paso de la fecha al formato de mongo
    \item Imputación de valores faltantes en \textit{CODIGO\_INTERNO}: mediante el rellenado de estos datos con los valores ``CÓDIGO\_INTERNO\_ID\_DESCONOCIDO''.
    \item Normalización de la columna \textit{tipo}: mediante el paso a mayúsculas y eliminación de los acentos de toda la columna
    \item Escritura del csv limpio final
\end{enumerate}

\subsubsection{Juegos}
\label{subsubsec:preprocessjuego}
Para el fichero \textit{JuegosSucio.csv} se han aplicado las siguientes transformaciones:

\begin{enumerate}
    \item Imputación de valores en \textit{DISTRITO} y \textit{CODIGO\_DISTRITO}: se han relacionado valores de distrito con códigos de forma unívoca, rellenando los valores faltantes en caso necesario. Esto se hace mediante la llamada a la función \texttt{imput\_missing\_district}.
    \item Imputación de valores en \textit{TIPO\_VIA}, \textit{NOMBRE\_VIA}, y \textit{NUM\_VIA}: se ha extraído toda la información posible de \textit{DIRECCION\_AUX} y rellenado los campos anteriores en caso posible.
    \item Fusión con \textit{areas\_limpias.csv}: se han asociado los juegos a un área mediante los campos \textit{CODIGO\_INTERNO} y \textit{NDP}. Esto se ha traducido en una columna nueva en la tabla de \textit{juegos} con el ID del área al que pertenece. Adicionalmente se ha completado la información faltante de cada tabla con información del otro en los casos posibles.
\end{enumerate}

\subsubsection{Meteo24}
\label{subsubsec:preprocessmeteo}
El fichero \textit{meteo24.csv} se ha restructurado para conseguir el formato pedido, el proceso de reestructuración es el siguiente:

\begin{enumerate}
    \item Se ha creado un nuevo dataframe con las siguientes columnas: \textit{Id}, \textit{Fecha}, \textit{Temperatura}, \textit{Precipitación}, \textit{Viento} y \textit{Estación}.
    \item Se ha creado un diccionario en python que permita asociar el código de la magnitud con la propia magnitud con tan solo las magnitudes que nos interesan.
    \item Para cada fila de meteo24 se ha tomado el valor de la magnitud, comprobando que era una de las magnitudes que nos interesan, el código de la estación, el valor del año y del mes, y se ha iterado por cada columna que corresponde a un día del mes
    \item Para cada valor de día se creaba una fecha completa (\%DD,\%MM,\%AAAA) y se tomaba el valor de la columna de ese día para esa magnitud. Con estos datos se rellena el dataframe nuevo de la siguiente manera.
    \begin{itemize}
        \item Si esa fecha y estación no existen en el nuevo dataframe se crea una nueva fila y se rellena con únicamente la magnitud que se ha encontrado en ese momento, por lo que se crea una fila con magnitudes sin valor a las que se tendrá que esperar para dar valor.
        \item Si esa fecha y estación ya existe en el nuevo dataframe se rellena la fila existente con el nuevo valor de la magnitud.
    \end{itemize}
    \item Tras pasar por todas las filas de \textit{meteo24.csv} se transforma la columna \textit{Viento} a un booleano, dado que la magnitud que se nos pide es si el viento es fuerte o no, sin embargo a través de meteo conocemos la velocidad de este.
\end{enumerate}

\newpage
\section{Validación de Esquemas}
\label{sec:validacion}
Para la validación de esquemas, se han desarrollado unos esquemas para cada csv que ha sido limpiado en el apartado anterior. Para ello, todos han seguido una estructura similar a la siguiente:

\lstset{style=python}
\begin{lstlisting}
db.createCollection("nombre\_de\_colección", {
    validator: {
        \$jsonSchema: {
            bsonType: "object",
            title: "Nombre\_de\_colección Validation",
            required: ["param1", "param2", "paramN"],
            properties: {
                param1: {
                    bsonType: "tipo1",
                    description: "descripción1"
                },
                param2: {
                    bsonType: "tipo2",
                    description: "descripción2"
                },
                paramN: {
                    bsonType: "tipo3",
                    description: "descripción3"
                }
            }
        }
    }
})
\end{lstlisting}
\end{document}
