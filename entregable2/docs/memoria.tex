\documentclass[]{article}
\usepackage{graphicx}
\usepackage[spanish]{babel}
\usepackage[a4paper, top=2.5cm, bottom=2.5cm, left=3cm, right=3cm]{geometry}
\usepackage[hidelinks]{hyperref}
\usepackage[T1]{fontenc}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{float}

\definecolor{miverde}{rgb}{0,0.6,0}

% style for listings (código)
\lstdefinestyle{python}{
    language=Python,
    backgroundcolor=\color{gray!2},     % Color de fondo
    basicstyle=\ttfamily,               % Tipo y tamaño de fuente
    keywordstyle=\color{blue}\bfseries, % Color para palabras clave
    stringstyle=\color{miverde},        % Color para cadenas
    commentstyle=\color{red},           % Color para comentarios
    showspaces=false,                   % No mostrar espacios
    showstringspaces=false,             % No mostrar espacios en las cadenas
    frame=single,                       % Poner un marco alrededor del código
    breaklines=true,                    % Romper las líneas largas
    captionpos=b,                       % Posición del caption
    tabsize=4,                          % Tamaño de las tabulaciones
    escapeinside={\%*}{*)},             % Para incluir código LaTeX en los listings
    morekeywords={self}                 % Palabras clave adicionales
}

\lstdefinestyle{bash}{
    language=shell,
    backgroundcolor=\color{gray!2},     % Color de fondo
    basicstyle=\ttfamily,               % Tipo y tamaño de fuente
    keywordstyle=\color{blue}\bfseries, % Color para palabras clave
    stringstyle=\color{miverde},        % Color para cadenas
    commentstyle=\color{red},           % Color para comentarios
    showspaces=false,                   % No mostrar espacios
    showstringspaces=false,             % No mostrar espacios en las cadenas
    frame=single,                       % Poner un marco alrededor del código
    breaklines=true,                    % Romper las líneas largas
    captionpos=b,                       % Posición del caption
    tabsize=4,                          % Tamaño de las tabulaciones
    escapeinside={\%*}{*)},             % Para incluir código LaTeX en los listings
    morekeywords={self}                 % Palabras clave adicionales
}

\lstset{basicstyle=\ttfamily}
\lstset{
    inputencoding=utf8,
    extendedchars=true,      % Permitir caracteres extendidos (acentos)
    literate=%
        {á}{{\'a}}1 {Á}{{\'A}}1
        {é}{{\'e}}1 {É}{{\'E}}1
        {í}{{\'i}}1 {Í}{{\'I}}1
        {ó}{{\'o}}1 {Ó}{{\'O}}1
        {ú}{{\'u}}1 {Ú}{{\'U}}1
}


%title
\title{Práctica 2} 

\author{Adrián Ferández Galán, César López Mantecón y Manuel Gómez-Plana Rodríguez}

\begin{document}

\begin{titlepage}
    \centering
   \includegraphics[width=0.9\textwidth]{uc3m.jpg} 
    {\Huge Universidad Carlos III\\
    
     \Large Arquitectura de Datos\\
     \vspace{0.5cm}
     Curso 2024-25}
    \vspace{2cm}

    {\Huge \textbf{Práctica 1.2} \par}
    \vspace{0.5cm}
    {\Large Migración de Base de Datos a MongoDB \par}
    \vspace{8cm}

   \textbf{Ingeniería Informática, Cuarto curso}\\
    \vspace{0.2cm} 
    Adrián Fernández Galán       (NIA: 100472182, e-mail: 100472182@alumnos.uc3m.es)\\
    César López Mantecón         (NIA: 100472092, e-mail: 100472092@alumnos.uc3m.es)\\
    Manuel Gómez-Plana Rodríguez (NIA: 100472310, e-mail: 100472310@alumnos.uc3m.es)
    \vspace{0.5cm}

   
    \textbf{Prof.} Lourdes Moreno López\\
    
    \textbf{Grupo: } 81   
    
\end{titlepage}
\newpage

\renewcommand{\contentsname}{\centering Índice}
\tableofcontents

\newpage
\section{Introducción}
\label{sec:introduccion}
En este documento se recoge el desarrollo de la segunda práctica de la asignatura Arquitectura de datos. A continuación, se especifica el preprocesado de los datos usando la biblioteca \textit{Pandas} de Python, la realización de la validación de esquemas de mongoDB y la carga de los csvs limpios a esta herramienta.

\newpage
\lstset{style=python}
\section{Preprocesado de Datos}
\label{sec:preprocesado}
En este apartado se describen las técnicas más comunes para el preprocesado de los datos sucios, así como las técnicas especificas para los csvs con datos menos genéricos. Para este preprocesado se ha usado la librería de Python \textit{Pandas}, siguiendo una metodología común para cada fichero que constaba de los siguientes pasos:

\begin{enumerate}
    \item Se carga el csv a limpiar en un \textit{dataframe} de \textit{Pandas}
    \item Se aplican técnicas de preprocesado como la normalización de los strings o imputación genérica de \textit{missing values}
    \item Se escribe el csv limpio a partir del \textit{dataframe} preprocesado
\end{enumerate}

\subsection{Técnicas de preprocesado comunes}
\label{subsec:preprocesadocomun}
Se han aplicado técnicas de preprocesado que son comunes a todos los ficheros, independientemente de cual se quiera limpiar. A continuación, se listan y explican las técnias más usadas:

\begin{itemize}
    \item \textbf{Normalización de strings}:

    Todos los datos categóricos han sido normalizados de manera que siempre estén en mayúscula y sin tildes. Esto se ha realizado empleando la siguiente función:

    \begin{lstlisting}[language=Python]
def change_accents(word):
    if type(word) != str:
        return
    for letter in range(len(word)):
        if word[letter] == "Á":
            word = word[0:letter] + "A" + word[letter + 1:]
        if word[letter] == "É":
            word = word[0:letter] + "E" + word[letter + 1:]
        if word[letter] == "Í":
            word = word[0:letter] + "I" + word[letter + 1:]
        if word[letter] == "Ó":
            word = word[0:letter] + "O" + word[letter + 1:]
        if word[letter] == "Ú":
            word = word[0:letter] + "U" + word[letter + 1:]
    return word
    \end{lstlisting}

    La cuál se llamaba de la siguiente manera:

    \begin{lstlisting}
dataframe.loc[indice, "COLUMNA_A_CAMBIAR"] = change_accents(valor["COLUMNA_A_CAMBIAR"].upper())
    \end{lstlisting}

    \item \textbf{Rellenado de fechas}

    Las fechas que tenían el valor ``fecha desconocida'' o que no tenían valor han sido rellenadas con el valor ``01/01/1970'' a través del siguiente código:

    \begin{lstlisting}
for indice, value in dataframe.iterrows():
    if not pd.notna(value["FECHA_INSTALACION"]) or value["FECHA_INSTALACION"] == "fecha_incorrecta":
        dataframe.loc[indice, "FECHA_INSTALACION"] = "01/01/1970"
    \end{lstlisting}

    \item \textbf{Rellenado genérico de \textit{missing values}}
    
    Las columnas que tenían valores nulos que no ha sido posible imputar han sido rellenadas con un valor fácilmente indetificable que sigue el formato ``NOM-COL\_DESCONOCIDO\_ID-FILA'' mediante la siguiente función:

    \begin{lstlisting}
def fill_missing_tipo(row,column,string_missing):
    if pd.isnull(row[column]):
        return f'{string_missing}_{row["ID"]}'
    return row[column]
    \end{lstlisting}

    Esta función se llama de la siguiente manera:

    \begin{lstlisting}
df["COLUMNA"] = df.apply(lambda row: fill_missing_tipo(row, "COLUMA", "COLUMNA_DESCONOCIDO"), axis=1)
    \end{lstlisting}

\end{itemize}

\subsection{Técnicas de preprocesado especificas}
\label{subsec:preprocessespecifico}

\subsubsection{Juegos}
\label{subsubsec:preprocessjuego}
Para el fichero \textit{JuegosSucio.csv} se han aplicado las siguientes transformaciones:

\begin{itemize}
    \item Imputación de valores en \textit{DISTRITO} y \textit{CODIGO\_DISTRITO}: se han relacionado valores de distrito con códigos de forma unívoca, rellenando los valores faltantes en caso necesario. Esto se hace mediante la llamada a la función \texttt{imput\_missing\_district}.
    \item Imputación de valores en \textit{TIPO\_VIA}, \textit{NOMBRE\_VIA}, y \textit{NUM\_VIA}: se ha extraído toda la información posible de \textit{DIRECCION\_AUX} y rellenado los campos anteriores en caso posible.
    \item Fusión con \textit{areas\_limpias.csv}: se han asociado los juegos a un área mediante los campos \textit{CODIGO\_INTERNO} y \textit{NDP}. Esto se ha traducido en una columna nueva en la tabla de \textit{juegos} con el ID del área al que pertenece. Adicionalmente se ha completado la información faltante de cada tabla con información del otro en los casos posibles.
\end{itemize}

\newpage
\section{Validación de Esquemas}
\label{sec:validacion}
Para la validación de esquemas, se han desarrollado unos esquemas para cada csv que ha sido limpiado en el apartado anterior. Para ello, todos han seguido una estructura similar a la siguiente:

\lstset{style=bash}
\begin{lstlisting}
db.createCollection("nombre\_de\_colección", {
    validator: {
        \$jsonSchema: {
            bsonType: "object",
            title: "Nombre\_de\_colección Validation",
            required: ["param1", "param2", "paramN"],
            properties: {
                param1: {
                    bsonType: "tipo1",
                    description: "descripción1"
                },
                param2: {
                    bsonType: "tipo2",
                    description: "descripción2"
                },
                paramN: {
                    bsonType: "tipo3",
                    description: "descripción3"
                }
            }
        }
    }
})
\end{lstlisting}

\newpage
\section{Carga de Datos en MongoDB}
\label{sec:mondongo}

\end{document}
